{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #!/usr/bin/env python\n",
    "# # coding: utf-8\n",
    "# # \n",
    "\n",
    "\n",
    "# ### PARSEO DE ARGUMENTOS\n",
    "\n",
    "# import argparse\n",
    "\n",
    "# parser = argparse.ArgumentParser(description='A script to process data for a range of years')\n",
    "\n",
    "# parser.add_argument('-y','--years', nargs='+', help='Set the range of years to process data for. Default is the current year and the next year', required=False, type=int, default=[2022, 2023])\n",
    "# parser.add_argument('-ow','--overwrite', nargs=1, required=False, default= True, help='Flag to specify if previous data should be overwritten. Default is True')\n",
    "\n",
    "# args = parser.parse_args()\n",
    "\n",
    "# overwrite = args.overwrite\n",
    "# startyr = args.years[0]\n",
    "# endyr = args.years[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "overwrite = 1\n",
    "startyr = 2024\n",
    "endyr = 2025\n",
    "name = \"202507\" # \"ARG\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "# Column names\n",
    "y_cols = ['CAT_OCUP', 'P47T', 'PP10E', 'PP10D', 'PP07K', 'PP07I', 'V3_M', 'PP07G4', 'CH16', 'T_VI', \n",
    "          'V12_M', 'TOT_P12', 'PP07G3', 'V5_M', 'PP07H', 'V2_M', 'PP10C', \n",
    "          'PP08D1', 'PP07J', 'CAT_INAC', 'CH07', 'CH08', 'P21', 'PP07G1', 'PP07G_59', 'PP07G2']\n",
    "\n",
    "x_cols1 = ['IX_TOT', 'P02', 'P03', 'AGLO_rk', 'Reg_rk', 'V01', 'H05', 'H06',\n",
    "       'H07', 'H08', 'H09', 'H10', 'H11', 'H12', 'H16', 'H15', 'PROP', 'H14',\n",
    "       'H13', 'P07', 'P08', 'P09', 'P10', 'P05', 'CONDACT']\n",
    "\n",
    "predecir1 = ['CAT_OCUP', 'CAT_INAC', 'CH07']\n",
    "\n",
    "x_cols2 = x_cols1 + predecir1\n",
    "predecir2 = ['INGRESO', 'INGRESO_NLB', 'INGRESO_JUB', 'INGRESO_SBS']\n",
    "\n",
    "x_cols3 = x_cols2 + predecir2\n",
    "predecir3 = ['PP07G1','PP07G_59', 'PP07I', 'PP07J', 'PP07K']\n",
    "\n",
    "# Columnas de ingresos. Necesitan una regresion...\n",
    "columnas_pesos = [u'P21', u'P47T', u'PP08D1', u'TOT_P12', u'T_VI', u'V12_M', u'V2_M', u'V3_M', u'V5_M']\n",
    "\n",
    "x_cols4 = x_cols3 + predecir3\n",
    "\n",
    "predecir4 = columnas_pesos\n",
    "y_cols4 = predecir4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# #####  TRAINING  #####\n",
    "\n",
    "# #####  Funciones clasificador y regresor  #####\n",
    "\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "# import os\n",
    "# import joblib\n",
    "\n",
    "# def fit_model(train_data, x_cols, y_cols, out_filename,\n",
    "#              model):\n",
    "#     X = train_data[x_cols]\n",
    "#     y = train_data[y_cols]\n",
    "    \n",
    "#     X, X_test, y, y_test = train_test_split(X, y, test_size=0.1) # less memory used\n",
    "    \n",
    "#     clf = model.fit(X.values, y.values) # fit model\n",
    "\n",
    "#     # Detect task type based on model class\n",
    "#     if isinstance(model, RandomForestClassifier):\n",
    "#         task = 'classification'\n",
    "#     elif isinstance(model, RandomForestRegressor):\n",
    "#         task = 'regression'\n",
    "#     else:\n",
    "#         task = 'unknown'\n",
    "\n",
    "#     # Evaluate if supported\n",
    "#     if task in ['classification', 'regression']:\n",
    "#         print(f\"Evaluating model: {out_filename}\")\n",
    "#         evaluate_model(clf, X_test, y_test, task=task)\n",
    "#     else:\n",
    "#         print(f\"âš ï¸ Unknown model type for evaluation: {type(model)}\")\n",
    "\n",
    "#     # save the model to disk\n",
    "#     if not os.path.exists('./modelos/'):\n",
    "#         os.makedirs('./modelos/')\n",
    "#     joblib.dump(model, out_filename, compress=3)\n",
    "#     print('saved model at: ' + out_filename)\n",
    "\n",
    "# #     print(sorted([(x, sys.getsizeof(globals().get(x))) for x in dir() if not x.startswith('_') and x not in sys.modules and x not in ipython_vars], key=lambda x: x[1], reverse=True)[:5])\n",
    "#     del clf\n",
    "#     del X; del y # liberar memoria eliminando los dataframes mas pesados\n",
    "\n",
    "\n",
    "# from sklearn.metrics import classification_report, confusion_matrix, mean_squared_error, r2_score\n",
    "# from sklearn.multiclass import OneVsRestClassifier\n",
    "\n",
    "# def evaluate_model(model, X_test, y_test, task='classification'):\n",
    "#     y_pred = model.predict(X_test)\n",
    "    \n",
    "#     if task == 'classification':\n",
    "#         print(\"ðŸ“Š Classification Report:\")\n",
    "#         print(classification_report(y_test, y_pred, zero_division=0))\n",
    "#         print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "\n",
    "#     elif task == 'regression':\n",
    "#         print(\"ðŸ“ˆ Regression Metrics:\")\n",
    "#         print(\"MSE:\", mean_squared_error(y_test, y_pred))\n",
    "#         print(\"RMSE:\", mean_squared_error(y_test, y_pred, squared=False))\n",
    "#         print(\"RÂ²:\", r2_score(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import joblib\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor, HistGradientBoostingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import (\n",
    "    classification_report, confusion_matrix,\n",
    "    mean_squared_error, r2_score\n",
    ")\n",
    "\n",
    "\n",
    "def evaluate_model(model, X_test, y_test, task='classification', target_names=None, target_col=None):\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    if task == 'classification':\n",
    "        print(f\"\\nðŸ“Š Report for target: {target_col or 'Unnamed'}\")\n",
    "        print(classification_report(y_test, y_pred, zero_division=0, target_names=target_names))\n",
    "        print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "\n",
    "    elif task == 'regression':\n",
    "        print(f\"\\nðŸ“ˆ Regression Report for target: {target_col or 'Unnamed'}\")\n",
    "        print(\"MSE:\", mean_squared_error(y_test, y_pred))\n",
    "        print(\"RMSE:\", mean_squared_error(y_test, y_pred, squared=False))\n",
    "        print(\"RÂ²:\", r2_score(y_test, y_pred))\n",
    "\n",
    "\n",
    "\n",
    "# def evaluate_model(model, X_test, y_test, task='classification', target_names=None):\n",
    "#     y_pred = model.predict(X_test)\n",
    "\n",
    "#     if task == 'classification':\n",
    "#         if y_test.ndim == 1 or isinstance(y_test, pd.Series):\n",
    "#             print(\"ðŸ“Š Classification Report:\")\n",
    "#             print(classification_report(y_test, y_pred, zero_division=0, target_names=target_names))\n",
    "#             print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "#         else:\n",
    "#             # Multi-output: iterate over columns\n",
    "#             for i, col in enumerate(y_test.columns):\n",
    "#                 print(f\"\\nðŸ“Š Report for target: {col}\")\n",
    "#                 print(classification_report(y_test[col], y_pred[:, i], zero_division=0))\n",
    "#                 print(\"Confusion Matrix:\\n\", confusion_matrix(y_test[col], y_pred[:, i]))\n",
    "\n",
    "#     elif task == 'regression':\n",
    "#         if y_test.ndim == 1 or isinstance(y_test, pd.Series):\n",
    "#             y_pred_flat = y_pred\n",
    "#             y_test_flat = y_test\n",
    "#         else:\n",
    "#             # average across columns (summary metric only)\n",
    "#             y_pred_flat = y_pred.ravel()\n",
    "#             y_test_flat = y_test.values.ravel()\n",
    "\n",
    "#         print(\"ðŸ“ˆ Regression Metrics:\")\n",
    "#         print(\"MSE:\", mean_squared_error(y_test_flat, y_pred_flat))\n",
    "#         print(\"RMSE:\", mean_squared_error(y_test_flat, y_pred_flat, squared=False))\n",
    "#         print(\"RÂ²:\", r2_score(y_test_flat, y_pred_flat))\n",
    "\n",
    "\n",
    "def fit_model(train_data, x_cols, y_cols, out_filename, model):\n",
    "    X = train_data[x_cols]\n",
    "    y = train_data[y_cols]\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)\n",
    "\n",
    "    clf = model.fit(X_train.values, y_train.values)\n",
    "\n",
    "    # Detect task type\n",
    "    if isinstance(model, RandomForestClassifier):\n",
    "        task = 'classification'\n",
    "    if isinstance(model, HistGradientBoostingClassifier):\n",
    "        task = 'classification'\n",
    "    elif isinstance(model, RandomForestRegressor):\n",
    "        task = 'regression'\n",
    "    else:\n",
    "        task = 'unknown'\n",
    "\n",
    "    if task != 'unknown':\n",
    "        print(f\"\\nðŸ“‚ Evaluating: {out_filename}\")\n",
    "        evaluate_model(clf, X_test, y_test, task=task)\n",
    "    else:\n",
    "        print(f\"âš ï¸ Unsupported model type: {type(model)}\")\n",
    "\n",
    "    # Save model\n",
    "    os.makedirs('./modelos/', exist_ok=True)\n",
    "    joblib.dump(model, out_filename, compress=3)\n",
    "    print(f\"âœ… Model saved at: {out_filename}\\n\")\n",
    "\n",
    "    # Cleanup\n",
    "    del clf, X, y, X_train, y_train, X_test, y_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/matias/anaconda3/envs/new_env/lib/python3.11/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“‚ Evaluating: ./modelos/clf1_2024_202507_CAT_OCUP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/matias/anaconda3/envs/new_env/lib/python3.11/site-packages/sklearn/base.py:458: UserWarning: X has feature names, but HistGradientBoostingClassifier was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“Š Report for target: CAT_OCUP\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "too many indices for array: array is 1-dimensional, but 2 were indexed",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[39], line 51\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;66;03m# Run each stage\u001b[39;00m\n\u001b[0;32m---> 51\u001b[0m \u001b[43mrun_stage\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_cols1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpredecir1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mclf1\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     52\u001b[0m run_stage(train_data, x_cols2, predecir2, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclf2\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     53\u001b[0m run_stage(train_data, x_cols3, predecir3, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclf3\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[39], line 31\u001b[0m, in \u001b[0;36mrun_stage\u001b[0;34m(train_data, x_cols, y_cols, stage_name)\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(out) \u001b[38;5;129;01mor\u001b[39;00m overwrite:\n\u001b[1;32m     30\u001b[0m     model \u001b[38;5;241m=\u001b[39m make_model()\n\u001b[0;32m---> 31\u001b[0m     \u001b[43mfit_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     32\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     33\u001b[0m \u001b[43m        \u001b[49m\u001b[43mx_cols\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx_cols\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     34\u001b[0m \u001b[43m        \u001b[49m\u001b[43my_cols\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mtarget_col\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     35\u001b[0m \u001b[43m        \u001b[49m\u001b[43mout_filename\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     36\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\n\u001b[1;32m     37\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[35], line 62\u001b[0m, in \u001b[0;36mfit_model\u001b[0;34m(train_data, x_cols, y_cols, out_filename, model)\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m task \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124munknown\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m     61\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mðŸ“‚ Evaluating: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mout_filename\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 62\u001b[0m     \u001b[43mevaluate_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     64\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mâš ï¸ Unsupported model type: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(model)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[35], line 24\u001b[0m, in \u001b[0;36mevaluate_model\u001b[0;34m(model, X_test, y_test, task, target_names)\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m i, col \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(y_test\u001b[38;5;241m.\u001b[39mcolumns):\n\u001b[1;32m     23\u001b[0m             \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mðŸ“Š Report for target: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcol\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 24\u001b[0m             \u001b[38;5;28mprint\u001b[39m(classification_report(y_test[col], \u001b[43my_pred\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m, zero_division\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m))\n\u001b[1;32m     25\u001b[0m             \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConfusion Matrix:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, confusion_matrix(y_test[col], y_pred[:, i]))\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m task \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mregression\u001b[39m\u001b[38;5;124m'\u001b[39m:\n",
      "\u001b[0;31mIndexError\u001b[0m: too many indices for array: array is 1-dimensional, but 2 were indexed"
     ]
    }
   ],
   "source": [
    "    \n",
    "##########################################################################################    \n",
    "################ Loop principal. Entrenar y guardar modelos  #############################\n",
    "##########################################################################################\n",
    "\n",
    "import pandas as pd\n",
    "from numpy import log10\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# Reusable model configuration\n",
    "def make_model():\n",
    "    return HistGradientBoostingClassifier(\n",
    "        learning_rate=0.05,\n",
    "        max_iter=300,\n",
    "        max_leaf_nodes=64,\n",
    "        early_stopping=True,\n",
    "        validation_fraction=0.1,\n",
    "        n_iter_no_change=20,\n",
    "        class_weight=\"balanced\",\n",
    "        random_state=42,\n",
    "        verbose=0\n",
    "    )\n",
    "\n",
    "\n",
    "# Unified stage runner\n",
    "def run_stage(train_data, x_cols, y_cols, stage_name):\n",
    "    for target_col in y_cols:\n",
    "        out = f'./modelos/{stage_name}_{yr}_{name}_{target_col}'\n",
    "        if not os.path.exists(out) or overwrite:\n",
    "            model = make_model()\n",
    "            fit_model(\n",
    "                train_data,\n",
    "                x_cols=x_cols,\n",
    "                y_cols=[target_col],\n",
    "                out_filename=out,\n",
    "                model=model\n",
    "            )\n",
    "\n",
    "            \n",
    "for yr in [str(s) for s in range(startyr, endyr)]:\n",
    "    print(yr)\n",
    "    try:\n",
    "        training_data = f'./../../data/training/EPHARG_train_{yr[2:]}.csv'\n",
    "        train_data = pd.read_csv(training_data)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"File {training_data} not found for year {yr}, skipping.\")\n",
    "        continue\n",
    "    \n",
    "\n",
    "    # Run each stage\n",
    "    run_stage(train_data, x_cols1, predecir1, \"clf1\")\n",
    "    run_stage(train_data, x_cols2, predecir2, \"clf2\")\n",
    "    run_stage(train_data, x_cols3, predecir3, \"clf3\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "new_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
